@flexiarg ai4ci/project-summary-core
@title AI4CI â€” Mid-Level Reasoning Pilot
@sigils [ðŸ§®/ç´¢ ðŸ“¡/å¾„]
@audience EPSRC reviewers
@tone plain-analytic
@allow-new-claims false
@factor Keen investigation (dhammavicaya)
@references [hdm/outline-first-detail-later hdm/human-machine-dialogue devmap-coherence/prototype-alignment-bridge stack-coherence/evidence-ledger stack-coherence/ready-blocked-triage stack-coherence/stack-blocker-detection devmap-coherence/next-steps-to-done]

! conclusion:
  The projectâ€™s core contribution is to test, in a tightly scoped pilot,
  whether the informal, mid-level reasoning moves inside mathematical
  solutions can be made explicit, validated, and shown to help different
  cohorts understand proofs.

  + IF:
    AI systems currently train on polished proofs and expositions that omit
    much of the exploratory reasoning and heuristic guidance that human
    mathematicians rely on when solving graduate-level problems.

  + HOWEVER:
    The remaining informal layers live in the textual wraparound of worked
    solutions and in oral explanations; extracting their structure requires a
    disciplined workflow, not just more model capacityâ€”AI proposals, human
    validation, and collective evaluation must be combined so that evidence
    about the reasoning layer is explicit.

  + THEN:
    Deliver a focused pilot that (a) selects a small set of graduate-level
    worked problems; (b) uses existing tools to propose links between
    informal phrases and formal steps; (c) has annotators accept, edit, or
    reject each proposal; and (d) tests the resulting dual-layer proofs in
    seminars with undergraduates, postgraduates, and professionals to see
    which cues genuinely support understanding.

  + BECAUSE:
    Once we know whether a stable mid-level reasoning layer can be captured
    from expositionâ€”and where it breaks downâ€”we can state clearly what kind
    of process-level data will be needed for future AI that aims to train
    humans, and what cannot be obtained from textual traces alone.

  + STATUS:
    status[ready]
    evidence[library/hdm/outline-first-detail-later.flexiarg:1]
    evidence[library/hdm/human-machine-dialogue.flexiarg:1]

  + NEXT:
    next[Assemble a cleared mini-corpus of graduate-level exam solutions with both symbolic steps and expository text, coordinating with data stewards for release notes.]
    next[Specify the annotation protocol (including AI proposal settings and review rubric) and register it in the evidence ledger before piloting.]
    next[Design the seminar prompts and coding scheme so clarity/confusion signals can be fed back into future iterations.]
