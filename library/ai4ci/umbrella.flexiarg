@flexiarg ai4ci/umbrella
@title AI4CI ‚Äî Human-Centred Future of AI
@sigils [üåê/‰πâ ‚ö°/ËÉΩ]
@audience EPSRC reviewers
@tone plain-analytic
@allow-new-claims false

! conclusion:
  Future AI can and should be built that can train humans in cognitively
  intense skills, which requires an explicit, structured account of the
  mid-level reasoning cues humans already use to understand complex work.

  + IF:
    Contemporary AI systems can solve many formal problems in domains like
    mathematics, but they typically learn from polished outcomes rather than
    from the reasoning processes that human learners depend on.

  + HOWEVER:
    These processes do not appear as full interaction logs; they survive
    mainly in the expository layer as informal hints, motivations, and
    tactic-describing phrases. We do not yet know whether these traces can
    be systematically identified, linked to precise steps, and represented
    as a stable structure that generalises across problems and cohorts.

  + THEN:
    Treat expository traces as candidates for an underlying reasoning layer
    and design a principled way to surface, examine, and test them, combining
    AI proposals, human validation, and collective evaluation.

  + BECAUSE:
    Only by making this tacit reasoning layer explicit can we both deepen our
    scientific understanding of how humans communicate complex thinking and
    provide the process-level structures that future AI will need in order to
    help people build expertise rather than merely reproduce correct answers.

  + NEXT:
    next[Develop and test a constrained workflow in mathematics that extracts, validates, and evaluates mid-level reasoning cues, and use the results to state clearly whether a recoverable ‚Äúreasoning layer‚Äù exists that AI could train on.]
